{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Msanii Inference\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q git+https://github.com/Kinyugo/msanii@main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "from msanii.config import (\n",
    "    Audio2AudioConfig,\n",
    "    InpaintingConfig,\n",
    "    InterpolationConfig,\n",
    "    OutpaintingConfig,\n",
    "    SamplingConfig,\n",
    ")\n",
    "from msanii.scripts import (\n",
    "    run_audio2audio,\n",
    "    run_inpainting,\n",
    "    run_interpolation,\n",
    "    run_outpainting,\n",
    "    run_sampling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_config = {\n",
    "    \"ckpt_path\": \"<path-to-pipeline-ckpt>\",\n",
    "    \"output_dir\": \"<path-to-output-directory>\",\n",
    "    \"batch_size\": 4,\n",
    "    \"num_frames\": 8_387_584,  # should divisible by the downsampling factor of the U-Net\n",
    "    \"output_audio_format\": \"wav\",  # ogg, mp3 ...\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\",  # cpu or cuda\n",
    "    \"dtype\": \"float16\",  # torch.dtype\n",
    "    \"num_inference_steps\": 20,\n",
    "    \"verbose\": True,\n",
    "    \"use_neural_vocoder\": True,\n",
    "    \"channels\": 2,  # mono or stereo\n",
    "    \"num_samples\": 16,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_config = OmegaConf.create(sampling_config)\n",
    "sampling_config = OmegaConf.merge(sampling_config, SamplingConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sampling(sampling_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio2Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2audio_config = {\n",
    "    \"ckpt_path\": \"<path-to-pipeline-ckpt>\",\n",
    "    \"output_dir\": \"<path-to-output-directory>\",\n",
    "    \"batch_size\": 4,\n",
    "    \"num_frames\": 8_387_584,  # should divisible by the downsampling factor of the U-Net\n",
    "    \"output_audio_format\": \"wav\",  # ogg, mp3 ...\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\",  # cpu or cuda\n",
    "    \"dtype\": \"float16\",  # torch.dtype\n",
    "    \"num_inference_steps\": 20,\n",
    "    \"verbose\": True,\n",
    "    \"use_neural_vocoder\": True,\n",
    "    \"data_dir\": \"<path-to-folder-with-audio-files>\",\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "    \"strength\": 0.1,  # controls how much noise is added; [0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2audio_config = OmegaConf.create(audio2audio_config)\n",
    "audio2audio_config = OmegaConf.merge(audio2audio_config, Audio2AudioConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_audio2audio(audio2audio_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_config = {\n",
    "    \"ckpt_path\": \"<path-to-pipeline-ckpt>\",\n",
    "    \"output_dir\": \"<path-to-output-directory>\",\n",
    "    \"batch_size\": 4,\n",
    "    \"num_frames\": 8_387_584,  # should divisible by the downsampling factor of the U-Net\n",
    "    \"output_audio_format\": \"wav\",  # ogg, mp3 ...\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\",  # cpu or cuda\n",
    "    \"dtype\": \"float16\",  # torch.dtype\n",
    "    \"num_inference_steps\": 20,\n",
    "    \"verbose\": True,\n",
    "    \"use_neural_vocoder\": True,\n",
    "    \"first_data_dir\": \"<path-to-folder-with-audio-files>\",\n",
    "    \"second_data_dir\": \"<path-to-folder-with-audio-files>\",\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "    \"ratio\": 0.5,  # controls how much of the first sample is in the interpolation\n",
    "    \"strength\": 0.1,  # controls how much noise is added; [0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_config = OmegaConf.create(interpolation_config)\n",
    "interpolation_config = OmegaConf.merge(interpolation_config, InterpolationConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_interpolation(interpolation_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpainting_config = {\n",
    "    \"ckpt_path\": \"<path-to-pipeline-ckpt>\",\n",
    "    \"output_dir\": \"<path-to-output-directory>\",\n",
    "    \"batch_size\": 4,\n",
    "    \"num_frames\": 8_387_584,  # should divisible by the downsampling factor of the U-Net\n",
    "    \"output_audio_format\": \"wav\",  # ogg, mp3 ...\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\",  # cpu or cuda\n",
    "    \"dtype\": \"float16\",  # torch.dtype\n",
    "    \"num_inference_steps\": 20,\n",
    "    \"verbose\": True,\n",
    "    \"use_neural_vocoder\": True,\n",
    "    \"data_dir\": \"<path-to-folder-with-audio-files>\",\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "    \"masks\": [],  # e.g [\"3-5,10-50\",\"4-10\", ...] for each sample if the folder,\n",
    "    \"eta\": 0.0,\n",
    "    \"jump_length\": 10,\n",
    "    \"jump_n_sample\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpainting_config = OmegaConf.create(inpainting_config)\n",
    "inpainting_config = OmegaConf.merge(inpainting_config, InpaintingConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inpainting(inpainting_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpainting_config = {\n",
    "    \"ckpt_path\": \"<path-to-pipeline-ckpt>\",\n",
    "    \"output_dir\": \"<path-to-output-directory>\",\n",
    "    \"batch_size\": 4,\n",
    "    \"num_frames\": 8_387_584,  # should divisible by the downsampling factor of the U-Net\n",
    "    \"output_audio_format\": \"wav\",  # ogg, mp3 ...\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\",  # cpu or cuda\n",
    "    \"dtype\": \"float16\",  # torch.dtype\n",
    "    \"num_inference_steps\": 20,\n",
    "    \"verbose\": True,\n",
    "    \"use_neural_vocoder\": True,\n",
    "    \"data_dir\": \"<path-to-folder-with-audio-files>\",\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True,\n",
    "    \"num_spans\": 2,  # number of half the num_frames outpaints\n",
    "    \"eta\": 0.0,\n",
    "    \"jump_length\": 10,\n",
    "    \"jump_n_sample\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpainting_config = OmegaConf.create(outpainting_config)\n",
    "outpainting_config = OmegaConf.merge(outpainting_config, OutpaintingConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_outpainting(outpainting_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c339664639c3e5019e3803d0baff2aab4fdaac0204aae143f6ed0f1a6cb76161"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
